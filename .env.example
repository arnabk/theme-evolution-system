# LLM Provider Configuration
# Supported providers: ollama (default), openai, gemini
LLM_PROVIDER=ollama

# Ollama Configuration (Local - Free)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# OpenAI Configuration (Cloud - Paid)
# Uncomment and set if using OpenAI
# OPENAI_API_KEY=sk-your_openai_api_key_here
# OPENAI_MODEL=gpt-4o-mini

# Google Gemini Configuration (Cloud - Paid)
# Uncomment and set if using Gemini
# GEMINI_API_KEY=your_gemini_api_key_here
# GEMINI_MODEL=gemini-1.5-flash
